import streamlit as st
import torch
import numpy as np
import cv2
from PIL import Image
import segmentation_models_pytorch as smp
import albumentations as A
from albumentations.pytorch import ToTensorV2

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Brain Tumor Segmentation", page_icon="ğŸ§ ")

st.title("ğŸ§  Brain Tumor Segmentation AI")
st.write("Upload an MRI image to detect the tumor area using SegFormer (MiT-B2).")

# 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· Ù„ØªØ³Ø±ÙŠØ¹ Ø§Ù„Ù…ÙˆÙ‚Ø¹)
@st.cache_resource
def load_model():
    device = torch.device("cpu") # Ù†Ø³ØªØ®Ø¯Ù… CPU ÙÙŠ Ø§Ù„Ø³ÙŠØ±ÙØ± Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠ
    model = smp.Segformer(
        encoder_name="mit_b2",
        encoder_weights=None,
        in_channels=3,
        classes=1,
    )
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ÙˆØ²Ø§Ù†
    try:
        model.load_state_dict(torch.load("best_model.pth", map_location=device))
    except FileNotFoundError:
        st.error("Error: Model file 'best_model.pth' not found.")
        return None
        
    model.to(device)
    model.eval()
    return model

model = load_model()

# 3. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
IMAGE_SIZE = 352
transform = A.Compose([
    A.Resize(IMAGE_SIZE, IMAGE_SIZE),
    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),
    ToTensorV2()
])

# 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
uploaded_file = st.file_uploader("Choose an MRI Image...", type=["jpg", "png", "jpeg"])

if uploaded_file is not None:
    # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©
    image = Image.open(uploaded_file).convert("RGB")
    st.image(image, caption="Uploaded MRI", use_column_width=True)
    
    if st.button("ğŸ” Detect Tumor"):
        with st.spinner("Analyzing..."):
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            img_np = np.array(image)
            augmented = transform(image=img_np)["image"].unsqueeze(0) # Ø¥Ø¶Ø§ÙØ© Batch Dimension
            
            # Ø§Ù„ØªÙˆÙ‚Ø¹
            with torch.no_grad():
                output = model(augmented)
                pred_mask = torch.sigmoid(output).squeeze().numpy()
                pred_mask = (pred_mask > 0.5).astype(np.uint8) * 255
            
            # ØªÙ„ÙˆÙŠÙ† Ø§Ù„Ù‚Ù†Ø§Ø¹ (Ù„Ù„Ø¹Ø±Ø¶ Ø§Ù„Ø¬Ù…ÙŠÙ„)
            # Ù†Ø­ÙˆÙ„ Ø§Ù„Ù‚Ù†Ø§Ø¹ Ù„Ù…Ù„ÙˆÙ† (Ø£Ø­Ù…Ø± Ù…Ø«Ù„Ø§Ù‹)
            mask_colored = np.zeros_like(img_np)
            mask_colored[:, :, 0] = pred_mask # Ø§Ù„Ù‚Ù†Ø§Ø© Ø§Ù„Ø­Ù…Ø±Ø§Ø¡ ÙÙ‚Ø·
            
            # Ø¯Ù…Ø¬ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù…Ø¹ Ø§Ù„Ù‚Ù†Ø§Ø¹
            img_resized = cv2.resize(img_np, (IMAGE_SIZE, IMAGE_SIZE))
            overlay = cv2.addWeighted(img_resized, 0.7, mask_colored, 0.3, 0)
            
            # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
            col1, col2 = st.columns(2)
            with col1:
                st.image(pred_mask, caption="Predicted Mask (Black/White)", use_column_width=True)
            with col2:
                st.image(overlay, caption="Tumor Overlay (Red)", use_column_width=True)
            
            st.success("Analysis Completed! âœ…")